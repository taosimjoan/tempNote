## HTTP 协议

* 超文本传输协议- ==在计算机世界里专门在两点之间传输超文本数据的约定和规范。==

* HTTP/1.1 强制要求 host 头，让互联网主机托管成为可能。

  * 链接慢
  * 不安全

* HTTP/2 高度兼容 HTTP/1.1，且改善了性能

  * 二进制协议--纯文本（1.1）
  * 可发起多个请求，废弃管道
  * 头部压缩，减少数据传输
  * 允许服务器主动推送
  * 加密通信

* 浏览器的角色称为用户代理

* CDN-（内容分发网络）存在于浏览器和服务器之间，应用了 HTTP 协议中的缓存和代理技术，代替源站响应客户端请求

  * 网络加速
  * 负载均衡
  * 安全防护 - WAF（网络应用防火墙）
  * 边缘计算

* 爬虫-是一种用户代理，可以自动访问 Web 的应用程序

* TCP/IP协议

  * 一系列网络通信协议的统称
  * 应用层、tcp 传输层、ip网际层、链接层
  * ip协议主要解决路由和寻址及如何在两点间传送数据，ip地址定位互联网上每台计算机。

* DNS：使用有意义的名字作为 ip 地址的等价替代

  * 域名级别从左到右依次升高，最右边是==顶级域名==
  * 域名到ip的映射就是域名解析

* URL/URI

  * DNS 和 IP 标记互联网上的主机，URI唯一的标记互联网上的资源

* HTTPS

  * HTTP  over SSL/TLS，负责加密通信的安全协议

* 代理-HTTP协议中请求方和应答方中间的一个环节，如CDN

  * 匿名代理：隐匿被代理的机器，外界只看到代理服务器
  * 透明代理：外界既知道代理，又知道客户端
  * 正向代理：靠近客户端，代替客户端向服务器发送请求
  * 反向代理：靠近服务端，代表服务器响应客户端请求

* TCP/IP 网络分层模型

  * 第一层：链接层：负责在以太网、wifi这样的底层网络发送原始数据包，网卡在这个层工作，使用MAC地址标记网络设备，也叫MAC层
  * 第二层：网际层，使用IP取代MAC地址
  * 第三层：传输层：保证数据在IP标记的两点之间可靠传输，TCP UDP
  * 第四层：应用层，如HTTP、FTP、SMTP、SSH

* OSI 网络分层模型

  * 第一层：物理层。网路的物理形式如光线、网卡
  * 第二层：数据链路层，相当于上述链接层
  * 第三层：网络层。相当于上述网际层
  * 第四层：传输层，相当于上述传输层
  * 第五层：会话层。维护网络连接状态，保持会话和同步
  * 第六层：表示层：将数据转为合适、可理解的语法、语意
  * 第七层：应用层，面向具体应用传输数据（第5、6、7层统一对应上述应用层）

  >四层负载均衡：工作在传输层，基于 TCP/IP特性，如 IP地址、端口号实现对后端服务器的负载均衡
  >
  >七层负载均衡：工作在应用层，如解析HTTP报文URL、主机名等，使用适当的策略转发给后端服务器

* 域名

  IP 层在 MAC 层之上，使用 IP 地址把 MAC 编号转换成四位数字，把数字形式的 IP 转为更有意义的名字，就出现了 DNS 域名系统

  * 域名最右边是顶级域名，层级向左依次降低
  * 最左侧是主机名，表明主机的用途（也不是绝对的）。==www==表示提供万维网服务，==mail==表示提供邮件服务
  * 域名本质上是名字空间系统，多级域名可区分不同的国家、地区、组织等

* 域名解析-DNS的核心系统是一个三层的树状、分布式结构

  1. 根域名服务器：管理顶级域名服务器，返回如==com==、==cn== 等顶级域名服务器的IP
  2. 顶级域名服务器：管理各自域名戏权威域名服务器，如==com==顶级域名服务器返回==apple.com==域名服务器的IP
  3. 权威域名服务器：管理自己域名下主机的IP，==apple.com==顶级域名服务器返回==www.apple.com==的IP地址

  * 全球共 13 组根域名服务器，域名的解析是从右向左解析的

* DNS 缓存

  * 许多大公司、网络运营商会建立自己的 DNS 服务器，作为用户 DNS 查询的代理，这些DNS服务器数量很多，且大部分部署在离用户很近的地方，如Google的==8.8.8.8==，微软的==4.2.2.1==
  * 操作系统会对 DNS 解析的结果缓存，若之前访问过一次，下次访问同一网址时直接在操作系统中就能拿到IP地址，此外，操作系统还有一个主机映射文件==hosts==

* 域名的玩法

  * 重定向。域名代替了IP，对外服务的域名不变，主机的IP可任意变动，当主机需要下线、迁移时，可更改DNS记录，实现重定向
  * 负载均衡
    * 因域名解析课返回多个IP，一个域名可对应多个主机，客户端收到多个IP后，自己可以根据轮询算法依次向服务器发起请求
    * 域名解析课配置内部策略，返回离客户端最近的主机或当前服务质量最好的主机

  > 域名解析会有多级缓存，浏览器先去查看自己的缓存中有没有，没有的话就像操作系统的缓存要，也没有的话就检查hosts 文件

* 真实的网络世界

  1. 若使用台式电脑，一般使用水晶头双绞线连接网口，由交换机接入固定网络。若使用手机等移动设备，则会通过蜂窝网络、wifi，由基站、无线热点接入移动网络
  2. 接入网络的同时，运营商会分配给你一个IP，可能是静态的，也可能是动态的，静态IP始终不变，动态IP可能在下次上网时就变了。
  3. 访问网站时，第一步做域名解析，从操作系统、本地DNS、根DNS、顶级DNS、权威DNS层层解析，有缓存的话，很快就能拿到结果
  4. CDN也会在DNS解析中起作用，DNS解析可能会给出 CDN 服务器的IP，因为 CDN 会缓存大部分资源，如图片、css等。
  5. 由 JAVA 等后台服务动态生成的页面是动态资源，CDN 无法缓存，只能从目标网站获取，HTTP请求经过无数的路由器、网关、代理，达到目的地
  6. 目标网站服务器对外表现是一个IP，为了扛住高并发，内部是一套复杂的结构，通常在入口是负载均衡设备，后面是许多服务器，构成一个集群
  7. 负载均衡设备首先访问系统里的缓存，通常有 memory 级的 redis 和 disk 级的 varnish
  8. 若缓存服务器也没有，负载均衡服务器就会把请求转发给应用服务器，如 Tomcat、Django，它们会访问后面的 mySql、mongoDb等数据库服务，然后把执行的结果返回个负载均衡设备，同时也可能在缓存服务器中存放一份
  9. 应用服务器输出到负载均衡设备这里，请求处理完成，就会按照原路返回，若这个资源允许缓存，经过CDN时也会做缓存
  10. 最后网站的响应数据回到了你的设备

* HTTP 报文结构-必须有header，可以没有body

  * 起始行：描述请求或响应的基本信息
  * 头部字段集合：key-value 的形式说明报文
  * 消息正文：实际传输的数据，如纯文本、图片、二进制流

  > HTTP对header的大小没有做限制，但各web服务器都不允许过大的请求头

  请求报文的起始行叫 请求行，包含三个部分 ==GET / HTTP/1.1==

  * 请求方法
  * 请求目标：通常是一个 URI
  * 版本号

  响应报文的起始行叫 状态行，包含三个部分 ==HTTP/1.1 200 OK==

  * 版本号
  * 状态码
  * 原因

  > 请求行或状态行加上头部字段就构成了 请求头或响应头
  >
  > HTTP 头字段很灵活，可以任意添加自定义头

* 头字段分类

  * 通用字段：请求头和响应头均可出现 如 Date
  * 请求字段：只能出现在请求头里，如 Host
  * 响应字段：只能出现在响应头里，如 server
  * 实体字段：实际上属于通用字段。但专门描述 body 的额外信息 如 content-length，表示报文 body 的长度，若没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输

* GET/HEAD

  GET操作搭配 URI 和 header 字段可以实现对资源更精细化操作

  * URI后使用==#==，可以获取页面后直接定位到某个位置
  * 使用==if-modified-since== 变成有条件的请求，当资源修改时才会获取
  * 使用==range==字段就是范围请求

  HEAD也是从服务器获取资源，服务器只会回传响应头，也就是资源的 ==元信息==

* URI

  完整格式

  > Scheme :// user:passwd host:port path?query#fragment
  >
  > 协议://主机:端口 路径 查询 哈希

  ==#fragment== 是 URI 定位的资源内部一个 锚点，可以在获取资源后直接跳到它指示的位置，但它仅能由浏览器这样的客户端使用，服务器看不到，浏览器不会把带==#fragment== 的URI发送给服务器。

* URI 编码

  URI 中只能使用 ASCII 码，对 ASCII 以外的字符集，会进行转义，转换为十六进制的字节值，然后前面加上一个==%==，对中文、日文等通常使用 UTF-8编码后转义。

* 状态码

  是一个十进制的三位数，分为五类 100-599

  * 1xx：提示信息，表示目前是协议处理的中间状态
  * 2xx：成功
    * 204 No Content - 与==200 ok==基本相同，但响应头后无 body 数据
    * 206 partial content：是分块下载或断点续传的基础，在客户端发送范围请求获取部分资源时出现，通常伴随着头字段==content-range==，表示响应报文 body 数据具体范围
  * 3xx：重定向
    * 301 永久重定向
    * 302 临时重定向： 浏览器不会做缓存优化
    * 304 not modified：用于==if-modified-since==等条件请求，表示资源未修改，用于缓存控制
  * 4xx：客户端错误
    * 400：通用错误，表示请求报文错误
    * 403 forbidden：表示禁止访问
    * 404 not found：表示找不到资源-也可能是不想让访问
    * 405 mehod not allowed：不允许使用某些方法
  * 5xx：服务器错误
    * 500:通用错误码
    * 501 not implemented ：表示客户端请求的功能不支持
    * 502 bad gateway：服务器作为网关或代理时返回的错误，表示后端服务器发生错误
    * 503 service unavailable ：表示服务器很忙，暂时无法响应，一般会有 retry-after 字段

* HTTP 特点

  * 可靠传输：基于 TCP/IP
  * 应用层协议
  * 请求-应答 通信模式
  * 无状态：没有记忆能力

* HTTP 优缺点

  * 简单、灵活易扩展-基本报文格式是==header+body==
  * 应用广泛、环境成熟
  * 无状态：既是优点也是缺点。没有记忆能力，不需要额外的资源标记状态，实现简单且减轻服务器压力，无状态也表示服务器都是相同的，可以很容易组成集群，实现高并发。当然也无法支持需要连续多个步骤的事物操作。
  * 明文：既是优点也是缺点。很容易查看和修改，调试方便，缺点是 HTTP 报文会被暴露
  * 不安全：除了明文，身份认证（证明你就是你）和完整性校验（数据传输中容易被篡改）也是HTTP所欠缺的
  * 性能：不算差、不够好，请求-应答模式造成==队头阻塞==。当顺序发送的请求序列中一个请求因为某种原因被阻塞，后面排队的所有请求也一并被阻塞。

* 实体数据

  TCP 因为是传输层协议，不关心 body 数据是什么，只要把数据发送到对方就行，HTTP 是应用层协议，数据到达后，还必须告诉上层协议是什么数据才行

  常见的 MIME 类型 

  * text：文本格式可读数据 ==text/html==、==text/plain== （纯文本）
  * image：==image/gif== 等
  * audio/video：音频视频如==audio/mpeg==
  * application：数据格式不固定，可文本，可二进制，需要有上层应用来解释。如==application/json==，若不知道数据类型，就会是==application/octet-strem== 即不透明的二进制

  仅有 MIME 类型还不够，为了节约带宽，数据还会压缩

  Encoding type 种类

  * gzip
  * deflate：zlib压缩格式
  * br：专门为 HTTP 优化的新压缩算法

  HTTP定义了==accept==请求头字段和==content==实体字段，用于客户端和服务端进行内容协商。

  UTF-8编码的 unicode 成为互联网上标准的字符集

  内容协商质量值==q==标明权重，最大值是1，最小值是0.01，默认是1，0表示拒绝

* 大文件传输

  * 数据压缩。==Accept-Encoding==是浏览器支持的压缩列表，数据压缩在处理文本时效果很好，但对于图片、音频等文件使用gzip也不会变小。

  * 分块传输。把文件拆开，分成小块，把这些小块分批发给浏览器，浏览器接收后再组装复原。浏览器和服务器就不用在内存中保存文件的全部，每次收发一小部分，网络也不会被打文件长时间占用。

    HTTP 中使用 ==chunked==分块传输编码，在响应头字段==Transfer-Encoding：chunked==表示，它和==Content-Length==是互斥的

  * 范围请求。获取一个打文件中的片段数据，相当于客户端的化整为零。

    范围请求不是 Web 服务器的必备功能，可以实现，也可以不实现，服务器必须在响应头里使用==Accept-Ranges：bytes==告知客户端“我是支持范围请求的”，若不支持，服务器发送==Accept-Ranges：none== 或者不发送==Accept-Ranges== 字段

    请求头 Range 是 HTTP 范围请求的专用字段，格式为==byte=x-y==，其中==x、y==是字节为单位的偏移量

    使用范围请求，看视频时可以根据时间节点计算出文件的Range，不用下载整个文件

    多段下载和断点续传就是基于范围请求来实现的

    * 先发个 HEAD，看服务器是否支持范围请求，同时获取文件大小
    * 开 N 个线程，每个线程使用 Range 划分出各自负责下载的片段
    * 下载意外中断，依据上次下载记录，用 Range 请求剩余部分

  * 多段数据。在 Range 头里使用多个==x-y==，一次性获取多个片段数据，此时需要一种特殊的MIME类型==multipart/byteranges==，表示报文的 body 由多段子界序列组成，还需要一个参数==boundary=xxx==给出段之间的分隔

* 连接管理

  * 短连接。HTTP/0.9（1.0）每次发送请求前先要建立连接，收到响应后会立即关闭连接，建立连接和关闭连接需要三次握手和四次挥手，传输效率很低

  * 长连接。（keep alive）把 TCP 建立连接和关闭连接的时间成本由原来的一个请求-应答分摊到多个请求-应答上。

    HTTP/1.1 默认开启长连接，只要向服务器发送了一次请求，后续的请求会重复利用第一次打开的 TCP连接，也可以在响应头中使用==Connection：keep-alive==告诉客户端支持长连接

    TCP 连接长时间不关闭，服务器必须在内存中保存它的状态，就占用了服务器资源，若有大量的空闲长连接，就会很快耗尽服务器的资源

    客户端可以在请求头里增加==Connection：close==告诉服务器，这次通信后就关闭连接

    服务器通常不会主动关闭连接，可以使用一些策略

    * Nginx 中使用==keepalive_timout==设置长连接的超时时间，若一段时间内没有任何数据收发就关闭
    * nginx使用==keepalive_request==设置长连接上发送的最大请求次数，达到后会主动断开

  * 队头阻塞

    队头阻塞与长短连接无关，由 HTTP 的==请求-应答==模式导致。

    HTTP 规定报文必须是==一收一发==，这就形成了先进先出的 ==队列==。队列里请求没有轻重缓急的优先级，只有入队的顺序，排在最前面的请求优先被处理。若队首的请求因为处理太慢耽误了时间，队列里后面所有的请求都必须等待。

  * 性能优化

    队头阻塞问题在 HTTP/1.1无法解决，只能缓解

    * ==并发连接==就是同时对同一个域名发起多个长连接，用数量解决质量问题。若每个客户端都想自己快，建立很多个连接，服务器的资源就会扛不住。浏览器对同一个域名的并发数做了限制，6-8 不等
    * ==域名分片==。对同一台服务器多开几个域名，也适用数量解决质量的思路

* 重定向

  重定向是用户无感知的。

  重定向需要两个 HTTP 请求，第一个返回 301 或 302 状态码，第二个请求是重定向的

  第一个请求的响应报文中 ==Location== 字段就是要重定向的 URI

  浏览器收到 301/302时会检查响应头中的 location 字段，若没有会报错，有的话就行跳转，Location 中的 URI 可以是相对路径，也可以是绝对路径

  301 重定向，浏览器会做适当优化。如历史记录，更新书签，爬虫看到301会更新索引库

  重定向会导致性能损耗，一次跳转会有两个请求。大量的重定向对服务器的影响不能忽略，站内重定向长连接可以复用，站外重定向要开两个连接，若网络连接质量差，会影响用户体验

  重定向要避免循环跳转

* Cookie机制

  HTTP 无状态的 优点是对服务器没有状态差异，很容易组成集群，缺点是无法支持需要记录状态的事物操作

  Cookie的传递需要 响应头字段==Set-cookie==和请求头字段==Cookie==

  浏览器第一次请求时，服务器创建一个独特的身份标识，格式是==key=value==，放进==Set-Cookie==字段中，浏览器收到响应报文，会把服务器给的身份标识保存起来，下次请求时自动把这个值放进==Cookie==字段里发送给浏览器。

  ==Cookie==是浏览器负责存储的，是浏览器绑定的，只在本浏览器中生效。

  ==Cookie==是服务器委托浏览器存储在客户端里的一些数据

* Cookie 的生命周期

  Cookie 的有效期可以用==Expires==和==Max-Age==两个属性设置

  * Expires：过期时间，用的是绝对时间
  * Max-Age：相对时间，单位是秒，浏览器收到报文的时间加上 Max-Age，得到失效时间
  * 两者可同时出现，优先采用 Max-Age

* Cookie 作用域

  让浏览器仅发送给特定的服务器和 URI，防止被盗用

  ==Domain==和==Path==制定了Cookie所属的域名和路径。

  浏览器发送 Cookie 前，先从 URI 中提取==host==和==path==，对比Cookie属性，若不满足，不会在请求头里发送 Cookie

* Cookie 的安全性

  JS 脚本==document.cookie==可以读写 Cookie 数据，会引起 XSS

  * HttpOnly：该属性会告诉浏览器，Cookie 只能通过浏览器的HTTP传输
  * SameSite：可防范 XSRF 攻击。设置为
    * ==SameSite=Strict==，严格限制Cookie不能随跳转跨站发送
    * ==SameSite=Lax==，允许 GET/HEAD 安全方法，禁止 POST
    * ==SameSite=none==，不限制
  * Secure：表示 Cookie 仅使用 HTTPS加密传输

* HTTP 缓存控制

  基于请求-应答模式，缓存可分为==客户端缓存==和==服务端缓存==

  * 服务器缓存控制

    服务器标记资源有效期字段是==Cache-Control==。里面的值==max-age=30==，表示30秒的有效时间。这里的==max-age==是从响应报文创建的时刻计算，不是客户端收到报文的时间计算（Cookie 的 Max-Age），包含了在传输中所有节点停留的时间

    其他属性

    * ==no_store==。不允许缓存
    * ==no_cache==。可以缓存，但使用前必须去服务器验证是否过期，是否有新版本
    * ==must-revalidate==。若缓存不过期可以使用，过期了需要去服务器验证

  * 客户端缓存控制

    浏览器也可以发送==Cache-Control==

    点击刷新时，浏览器会在请求头里加一个==Cache-Control：max-age=0==，所以浏览器不会使用缓存

    ==Ctrl+F5==强制刷新，浏览器实际发送了一个==Cache-Control：no-cache==

    点击前进后退按钮，就会发现没有发送网络请求，读的是缓存，重定向也使用了缓存。因为这些操作不会在请求头加上==Cache-Control==

  * 条件请求

    浏览器用==Cache-Control==做缓存控制，只是刷新数据，不能很好利用缓存，因为缓存会失效，使用前还要去服务器验证

    浏览器可以用两个连续的动作

    * 先发一个 HEAD，获取资源的元信息，然后与缓存比较，没有改动就使用缓存
    * 否则再发一个 GET，获取新版本

    但两个网络请求的成本太高了

    HTTP定义了==If==开头的条件请求，专门检验资源是否过期，验证的责任也交给服务器

    常用的有两个，一共是5个

    * If-modified-since 和 last-modified
    * if-None-Match和ETag

    若资源没有变，返回 304

    浏览器第一次请求时，服务器返回==last-modified==或==etag==

    第二次请求时，浏览器使用==if-modified-since==带上上次返回的==last-modified==值或者使用==if-none-match==带上上次的==etag==的值，传给服务器做验证

    Etag是资源的唯一标识，解决修改时间无法区分文件变化的问题

    304 和 200

    * 200:表示没有向服务器发起请求，使用的是浏览器本地资源
    * 304:表示向服务器发起请求，但响应文件没有变化，用的是浏览器缓存

  * 代理服务

    在客户端和服务器之间插入的一个中间环节，也是一台服务器。转发上下游的请求和响应

    代理处在 HTTP 通信的中间位置，对上屏蔽了真实的客户端。对下屏蔽了真实的服务器

    代理的功能

    * 负载均衡。代理屏蔽了源服务器，就可以掌握请求的分发大权
    * 健康检查。监控后端服务器，发现有故障及时踢出集群
    * 安全防护。限制IP或流量，低于网络攻击和过载
    * 加密卸载。对外网使用SSL/TLS加密通信认证，内网不加密，消除加密成本
    * 数据过滤。拦截上下行数据，任意指定策略修改请求或响应
    * 内容缓存。暂存、复用服务器的响应

* HTTP 缓存代理

  支持缓存控制的代理服务。

  HTTP服务端的缓存，主要由代理服务器实现，源服务器系统内部也会有各种缓存（redis varnish）

  * 缓存代理服务

    没有缓存的时候，代理服务器每次都是直接转发客户端和服务端的报文，有了缓存之后

    * 把报文转发给客户端
    * 把报文存入自己的 cache 里

    下次再有相同的请求，代理服务器直接发送304或缓存数据，不必从源服务器那里获取，降低了客户端的等待时间，节约了源服务器的带宽。

    代理服务器面向源服务器时是客户端，面向客户端时是服务器，因此==它可以用客户端的缓存控制策略，也可以用服务端的缓存控制策略==，同时它并不是数据的消费者和生产者，所以还==需要一些新的Cache-Control属性来约束==

  * 源服务器的缓存控制

    前面4种服务端的==Cache-Control==属性，max-age、no_store、no_cache、must-revalidate，可以约束客户端，也可以约束代理。

    客户端的缓存只是自己使用，代理的缓存可能会为很多客户端提供服务，缓存需要多些限制

    * private：表示缓存只在客户端保存，是用户私有的
    * public：缓存完全开放，谁都可以保存

    其次缓存失效后重新验证也要分开

    must-revalidate 是只要过期就必须回源验证，而==proxy-revalidate==只要求代理缓存过期后必须验证，客户端不必回源

    代理专属属性==no-transform==。有时代理会对缓存的数据做一些优化，如把图片生成 png、webp等几种格式，方便今后的处理，而该属性会禁止这样做，必须保持原样。

    缓存的生存时间可以用==s-maxage==，只限定在代理上存多久

    ==源服务器在设置完 Cache-Control 后必须为报文加上 last-modified 或 Etag==否则客户端和代理无法使用条件请求验证缓存是否有效，也不会有 304 缓存重定向

  * 客户端的缓存控制

    客户端在 HTTP 种面对代理和源服务器，也要区分对待

    max-age、no_store、no_cache，同样作用域代理和源服务器，关于生存时间，多了两个新属性

    * max-stale：可接收的过期时间，若代理上的缓存过期了也能接受，但不能过期太多，超过 x 秒就不会要
    * min-fresh：可接受的新鲜时间。缓存必须有效，且必须在 x 秒后依然有效

    有时客户端还会有一个 only-if-cached 属性，表示只接受代理缓存，不接受源服务器的响应，若代理上没有缓存或缓存过期，应该返回 504（Gateway Timeout）

* 强缓存，指的是 EXpire 和 Cache-Control 缓存控制，协商缓存指的是条件请求，f5 刷新会跳过 强缓存，但是会检查协商缓存，ctrl+f5 直接从服务器加载，跳过强缓存和协商缓存。

#### HTTPS

HTTP 的无状态在 Cookie后得到了解决，明文和不安全 需要引入 HTTPS 解决。

* HTTP 不安全

  * 天生明文，传输过程完全透明，报文可以被截获、伪造、修改，数据不可信
  * 如代理服务器，可以在上下行添加或删除部分头字段，也可用黑白名单过滤 body 的关键字，甚至直接发送虚假请求、响应。

* 安全的四个特性

  * 机密性。对数据保密，只能有可信的人访问
  * 完整性。数据在传输中，没有被篡改
  * 身份认证。确认对方的身份，保证消息只发送给可信的人
  * 不可否认。不能否认已发生过的行为

* HTTPS

  除了协议名 http 和默认端口 80，HTTPS 在语法、语义上和 HTTP 完全一样

  与 HTTP 最大的区别在于，它能够鉴别 危险网站，尽最大可能保证上网安全

* SSL/TLS

  安全套接层，后被改名为 TLS 标准化

  在 OSI 模型的第五层（会话层）

  TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等子协议组成，综合使用对称加密、非对称加密、身份认证等密码学前沿技术

  浏览器和服务器在使用 TLS 建立连接时要选择一组恰当的加密算法实现安全通信，这些算法的组合称为==密码套件==

  >密码套件的格式：密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法

* 对称加密和非对称加密

  加密前的消息是明文，加密后的乱码是密文，使用密钥还原明文的过程叫解密，加解密的操作是加密算法。

  ==所有的加密算法都是公开的，算法使用的密钥必须保密==

  密钥就是一串数字，度量单位是 位（bit）。

  * 对称加密

    加密和解密使用的密钥是同一个，如AES 、ChaCha20，只要保证密钥的安全，整个通信过程就有了机密性。

    对称加密算法还有一个分组模式的概念，==它可以让算法用固定长度的密钥加密任意长度的明文==，分组模式 AEAD在加密的同时增加了认证功能

  * 非对称加密

    对称加密有一个问题：如何把密钥安全的传递给对方。

    ==非对称加密解决密钥交换的问题。==

    它有两个密钥，公钥和私钥。公钥可以给任何人使用，私钥必须严格保密。公钥加密后只能用私钥解密，私钥加密后也只能用公钥解密。

  * 混合加密

    非对称加密没有密钥交换的问题，但它们基于复杂的数学难题，运算速度很慢

  * TLS 使用混合加密的算法

    * 通信开始使用非对称加密，解决密钥交换的问题
    * 用随机数产生对称加密算法使用的 会话密钥，用公钥加密
    * 对方拿到后用私钥解密，取出会话密钥，就实现了对称密钥的交换，后续就使用对称加密

* 数字签名和证书

  混合加密实现了机密性，但无法保证完整性和身份认证。如可以窃听足够多的密文进行修改、重组，或者伪造身份发布公钥

  * 摘要算法-实现完整性

    摘要算法可以理解为一种特殊的压缩算法，能把任意长度的数据压缩成固定长度且独一无二的摘要字符串，也可以理解为单向加密算法，只有算法，没有密钥。

    摘要算法保证了数字摘要和原文完全等价，只要在原文后附上摘要，就能保证数据的完整性。

    网站收到消息后，也计算一下消息摘要，若完全一致，表明消息没有修改。

    不过摘要算法不具有机密性，若黑客修改消息后连摘要也一起修改，网站还是无法鉴别完整性。因此使用会话密钥加密消息和摘要。

  * 数字签名-实现身份认证和不可否认

    黑客可以伪装成网站窃取信息，也可以伪装成你，向网站发送支付、转账等消息。

    现实生活中，解决身份认证的手段是签名和盖章，TLS中就是==私钥==。

    使用私钥加上摘要算法，就能实现数字签名，同时实现==身份认证和不可否认==

    实现数字签名，就是==用私钥加密原文的摘要==

    签名和公钥一样完全公开，但这个签名只能有私有对应的公钥才能解开。拿到摘要后，再对比原文验证完整性。

  * 数字证书和 CA

    综合对称加密，非对称加密，摘要算法，我们就实现了安全的四大特性。这里还有一个==公钥的信任==问题。

    公认的可信的第三方CA（证书认证机构）构建公钥的信任链。

    CA 对公钥进行签名，实现==数字证书==

    小点的 CA 可以让大 CA 签名认证，最后就是 Root CA，只能自己证明自己，叫自签名证书或根证书。

    有了证书体系，操作系统和浏览器内置了各大CA的根证书，只要服务器发过来证书，就可以验证证书里的签名，顺着证书链，一层层直到找到根证书，就能确认证书是可信的，从而里面的公钥也是可信的。

  * 证书体系的弱点

    证书体系是目前整个网络世界里的基础安全设施，但绝对的安全是没有的

    若 CA失误或被欺骗，签发了错误的证书，虽然证书是真的，但网站是假的

    或者 CA 被黑客攻陷，或 CA 有恶意，因为根证书是信任的源头，所以整个信任链里所有的证书都不可信。

    因此出现了 证书吊销列表和在线证书状态协议，及时废止有问题的证书。

  

* HTTPS 建立连接

  浏览器先从URI中提取协议名和域名，因为协议是HTTPS，就知道默认端口是443，再用DNS解析域名，然后三次握手建立TCP连接

  TCP连接建立后，还需要另一个握手过程，在TCP上建立安全连接，然后收发 HTTP 报文。

  * TLS 握手过程

    TCP建立连接后，浏览器先发一个 Client Hello 消息，里面有客户端版本号、支持的密码套件，还有一个随机数用于生成会话密钥

    服务器收到后，会返回一个 Server Hello，对一下版本号，从客户端列表中选一个密码套件，也生成一个随机数返回

    然后服务器为了证明自己的身份，把证书发给客户端

    证书发送后，发送 Server Key Exchange，里面包含公钥，用于实现密钥交换算法，再加上自己的私钥签名认证

    客户端收到证书后，会验证证书的有效性，再用证书公钥验证签名。

    然后客户端按照密钥套件要求，也生成一个公钥，发送给服务器

    此时客户端和服务端都拿到了密钥交换算法的两个参数（上述两个公钥），用特定算法，算出一个 per-master，也是一个随机数

    然后根据 三个随机数，客户端和服务端就可以生成用于加密会话的主密钥 Master Secret

    主密钥不是最终的用于通信的会话密钥，还会扩展出更多密钥，如客户端发送的会话密钥，服务端发送用的会话密钥，避免一个密钥带来的安全隐患。

    有了主密钥和派生的会话密钥，客户端会把之前发送的数据做个摘要，再加密一下，让服务做个验证。服务器也是同样操作，双方都验证加密解密OK，握手结束

* HTTPS 连接优化

  HTTPS 连接大致划分为两个部分

  * 建立连接时 非对称加密握手
  * 握手后对称加密报文传输

  **硬件优化**

  HTTPS是 CPU 计算密集型

  * 更快的 CPU，最好内建 AES 优化，可加速握手，加速传输
  * SSL 加速卡，加解密时调用他的 API，让专门的硬件做非对称加解密
  * SSL 加速服务器

  **软件优化**

  * 软件升级 
  * 协议优化：选择 TLS 1.3，选择高性能的椭圆曲线、加密算法

  **证书优化**

  服务器需要把自己的证书链发送给客户端，然后客户端逐一验证

  * 证书传输。选择椭圆曲线证书
  * 证书验证。证书验证很复杂，处理要用公钥验证多个证书签名外，证书还可能被撤销失效，客户端需要访问 CA，下载 CRL（证书吊销列表）或 OCSP（在线证书查验），又会产生 DNS 查询，建立连接，收发数据等

  **会话复用**

  TLS 握手的重点是算出 主密钥。主密钥每次连接都需要重新计算，就有些浪费了。可以缓存一下主密钥，这就是会话复用。

  会话复用分两种

  * Session ID：客户端和服务器首次连接后各自保存一个会话的 ID，内存里存储主密钥和其他相关信息。当客户端发起连接时发送一个 ID，服务器就在内存里找，找到就直接用主密钥恢复会话状态。跳过证书验证和密钥交换。

    缺点是，服务器必须保存每一个客户端的会话数据，对于百万或更大级别用户的网站来说，存储量成了问题

  * Session Ticket：会话票证。类似于 Cookie，存储的责任转移到了客户端。服务器用==new session ticket==消息发送给客户端，让客户端保存，重连的时候，客户端使用 ==session_ticket==发送ticket，服务器解密后验证有效期，就可以恢复会话。

#### HTTP2

* 兼容 HTTP/1：语义层不做任何修改，如请求方法、URI、状态码、头字段等概念保持不变。语法层面变更了 HTTP 报文的传输格式。

* 头部压缩：开发了专门的 HPACK 算法，在客户端和服务端建立字典，用索引表示重复的字符串

* 二进制格式：报文采用二进制格式，把原来的==header+body==的消息打散为数个小片的 二进制 帧，header 帧存放头数据，Data 帧存放实体数据。数据分帧后，==header+body==的报文结构就完全消失了，协议看到的只是一个小小的碎片。

* 虚拟的流：它是二进制帧的双向传输序列，同一个消息往返的帧会分配一个唯一的流ID。可以看作是一个虚拟的数据流，在里面是一串有先后顺序的的数据帧，这些数据帧按照次序组装起来就是HTTP/1里的请求报文和响应报文。HTTP/2可以在一个 TCP 连接用流同时发送多个碎片化的消息，就是多路复用--多个往返通信都复用一个连接来处理。多个请求响应之间没有顺序关系，不需要排队，也就不会出现对头阻塞问题。在流的层面，消息是一些有序的帧序列，在连接层面看，消息是乱序收发的帧。

  HTTP/2 还添加一些控制帧管理虚拟的流，实现了优先级和流量控制。

  HTTP/2一定程度上改变了请求-应答工作模式，服务器也可以新建流主动向客户端发送消息。

* 强化安全：出于兼容，HTTP/2 延续了明文的特点，不过格式是二进制，但HTTPS是大势所趋，主流浏览器只支持加密的 HTTP/2，事实上的 HTTP/2是加密的

* 连接前言

  HTTP/2事实上基于 HTTPS，在收发数据之前，会有 TCP握手和 TLS 握手，之后，客户端要发送一个连接前言，来确认建立 HTTP/2 连接。这是个标准的 HTTP/1 请求报文，使用纯文本的 ASCII 码。

* HPACK 算法

  专门为压缩 HTTP 头部制定的。它是有状态的算法。需要客户端可服务器个字维护一份索引表，也就是字典，压缩和解压缩就是查表和更新表的操作。

  HTTP/2 为常用的头字段定义了一个只读的静态表。全是==key-value==的形式。若表里只有key，没有 value，或自定义的字段，就需要使用动态表，它添加载静态表后面，结构相同，但会在编码解码时随时更新。

  如第一次发送请求时==user-agent==字段有一百多个字节，压缩发送后，客户端和服务端都更新自己的动态表，添加一个新的索引，下次发送时，直接用一个字节发送编号就行。

* 流与多路复用

  HTTP/2 连接上，虽然帧时乱序收发的，只要它们有相同的流ID，就属于一个流。且在这个流里面，帧有着严格先后顺序。

  概念上，一个HTTP/2的流等同于一个HTTP/1里的==请求-应答==，在HTTP/1中一个==请求-响应==报文来回一是一次HTTP通信，在HTTP/2里一个流也承载了相同的功能。

  流的特点

  * 可并发，一个HTTP/2连接上可同时发出多个流传输数据。
  * 客户端和服务端都可以创建流，互不干扰。
  * 流是双向的。一个流里面客户端和服务器都可以发送或接收数据帧，也就是一个==请求-响应==来回
  * 流之间没有固定关系，彼此独立，但流内部的帧有严格顺序
  * 流可以设置优先级
  * 流ID不能重复，只能顺序递增，客户端发起的ID是奇数，服务端发起的ID 是偶数。
  * 流上发送 ==RST_STREAM==帧可随时终止流、取消接收或发送。
  * 第 0 号流比较特殊，不能关闭，也不能发送数据帧，只能发送控制帧。

* HTTP/2 缺点

  * 在TCP级别上还是存在队头阻塞
  * 移动网络中发生 IP 切换的时候，下层 TCP 必须重连，再次握手，且之前连接里积累的 HPACK 字典也会消失，必须重头计算。
  * HTTP/2 对一个域名只开一个连接，若这个连接出问题，整个网站的体验也就变差了。HTTP/1 本来就慢，而且还会对一个域名开6-8个连接，最多时其中一两个连接会更慢，其他不受影响。

* 精灵图、资源内联、域名分片会对HTTP/2 性能优化产生反效果。

  HTTP/2使用小颗粒化资源，优化了缓存。使用精灵图相当于传输大文件，大文件会延迟客户端的处理执行，且缓存失效的开销很昂贵，很小数量的数据更新就会使整个精灵图失效，需要重新下载。HTTP/1中使用精灵图主要是为了减少请求。

  HTTP/1使用内联资源也是为了减少请求，内联资源无法独立缓存，破坏了HTTP/2的多路复用和优先级策略（标签上直接写样式，图片 bas64引入）

  域名分片是为了突破浏览器每个域名下的同时连接数，HTTP/2中多路复用解决了这个问题

#### HTTP3

HTTP/2 进行了如头部压缩、二进制分帧、虚拟的流与多路复用，性能比 HTTP/1 有了很大提升，基本上解决了队头阻塞。

上述的手段都是发生在应用层。

在TCP层，TCP把 HTTP/2的流拆包，依次发送。若出现丢包的情况，TCP为了保证可靠传输，有==丢包重传==机制，丢失的包必须等待重新传输确认。即使其他的包已经收到，也只能放在缓冲区。这样就又出现了队头阻塞。

Google 推出了新的协议==QUIC==，也就是 HTTP/3，目前处于草案阶段。一个关键的改变是把下层的 TCP 换成了 UDP。UDP 是无序的，包之间没有依赖关系，从根本上解决了队头阻塞。

UDP是无连接的，不需要握手和挥手，天生比TCP快。

因为 UDP 简单、不可靠，在它之上，把TCP的那一套连接管理、流量控制等搬了过来，打造出一个全新的可靠传输协议。